{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNAseq in a nutshell: From FASTQ files to differential expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last week we learned to quantify gene expression using arrays. This technology is still used in and has some advantages, but a much more widely used approach is measuring transcriptome abundance using high throughput sequencing.\n",
    "\n",
    "We will start this session by describing the structure and quality control measures used for fastq files. So, it is important that before you start the next two sessions, you understand how these files are generated as part of an RNAseq experimental pipeline. This is composed of two steps: library generation and high throughput sequencing. \n",
    "\n",
    "**Library generation:** RNA extracted from cells, model organism or tissue undergoes a procedure that converts the RNA into DNA while attempting to preserve the relative abundance of the different transcripts. It is important to remember that the total RNA in a cell is usually composed of mostly rRNA, which is usually depleted in the process of library prep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.** Take a look at figure 1a in the paper by Martin et al. which we provided for you on Canvas, when going from step 3 to 4 primers need to be added for the reverse transcriptase, usually two types are used, which primers would you used if you would like to make sure that you are sequencing only mRNA? (If you have never heard of cDNA before, look it up using google)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**High throughput sequencing:** Many technologies for massively parallel sequencing have been introduced over the years but definitely the most popular is the Illumina Sequencing-By-Synthesis (SBS) technology. The DNA fragments that undergo SBS are the ones depicted in step 7 in figure 1a mentioned above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.** Take a look at an introduction video by <a href=\"https://www.youtube.com/watch?v=fCd6B5HRaZ8&ab_channel=Illumina\" target=\"_blank\">Illumina on SBS</a>, Illumina sequencing has limitations on the size of the fragments that can be sequenced, too short or too long DNA fragments cannot be accurately sequenced. Based on this video, can you guess which step in the process is responsible for this limitation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that sequencing can be done using either single or paired-end reads, as the fragments are usually longer than the number of SBS cycles, a paired-end read would capture the full sequence of the fragment by sequencing the two ends and filling the middle part using the genomic of transcriptome reference sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of the FASTQ file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Illumina sequencing reads are stored in FASTQ files, in these files every read is stored as four rows as follows:\n",
    "\n",
    "* Line 1:\tSequence ID – will always start with @ and is a unique ID for the read, this line is important because in many cases each sequencing cluster will have more than one read (like paired end and sample barcode) which will need to be matched.\n",
    "* Line 2: Sequence – The actual sequence consisting of the four nucleotides and N in cases where the precise nucleotide could not have been determined.\n",
    "* Line 3: Quality ID – This line will always start with + which in some cases will be followed by and read quality score encoded in ASCII\n",
    "* Line 4: Quality score – Note that this line will contain the same number of characters as the sequence line, every letter encodes the quality of the corresponding nucleotide in the sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.** We have provided an example FASTQ file in your directory (sample.fastq), open a terminal and use your unix skills to look at the top lines of the file. What is the nucleotide sequence of the 10th read? How many reads total does this file contain? (remember that each read is four lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing FASTQ files quality and sequence composition with FASTQC \n",
    "\n",
    "FASTQC is an extremely convenient tool that you should use as your first step in testing the quality of an Illumina NGS run. FASTQC will analyze the nucleotide composition and sequence quality scores of your run and will output and html file for each `fastq` file summarizing the results. \n",
    "\n",
    "We have provided you a **very** small snippet of the full `fastq` file. Let's run it on this small bit of data. To do that,\n",
    "\n",
    "- Open up a UNIX terminal\n",
    "- Make directory named `tmp` in your main, home directory (e.g., `~/tmp`)\n",
    "- Run fastqc on the command line within your RNASeq-I working directory:\n",
    "       \n",
    "    $> fastqc *.fastq\n",
    "       \n",
    "In general, this will analyze each `.fastq` file in your directory and summarize the quality measures for each file and ouptut to an html file. In this case, you only have one file to analyze (`sample.fastq`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4.** Open the resulting .html. How many reads were analyzed in this sample file?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full `fastq` file for these data is quite large (~24Gb!).\n",
    "\n",
    "So we have provided an example `fastqc` output file with the result of this tool run on the full data (`full_fastqc.html`).\n",
    "\n",
    "Open this file (you might need to download it to your computer) and explore the different summary statistics. Take a look at the per base sequence content, note the difference in nucleotide distribution at the begging of the reads compared to the middle of the reads. This is also reflected in the k-mer count. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5.** What is the 2nd most overrepresented kmer? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6.** What possible sources in the process of data generation could generate these k-mer count biases? (Hint: Think about library prep.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping of reads to the genome/transcriptome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to map the reads, representing RNA fragments, to a reference sequence library (as the genome) in order to convert the `fastq` files containing DNA fragments to a gene-based value associated with expression levels. \n",
    "\n",
    "In the early days of RNA-Seq, mapping was done mostly against the genome using aligners build to utilze \"short\" reads (150bp or less). Because reads are short - and do not capture a full transcript, this creates one additional layer of complexity - one will identify reads from varing splice isoforms that cross exon boundaries. (This is in contrast to other types of sequencing data generation, e.g. ChIP-Seq, which do not carry this complexity). \n",
    "\n",
    "One popular splicing aware aligner is [STAR](https://github.com/alexdobin/STAR) (Spliced Transcripts Alignment to Reference) which is considered a state-of-the-art aligner for this task.\n",
    "\n",
    "An alternative approach, which we will use here, is instead to map reads on a database of already assembled transcripts. The three leading algorithms for doing this are:\n",
    "\n",
    "[Salmon](https://combine-lab.github.io/salmon/)\n",
    "<br> [kallisto](https://pachterlab.github.io/kallisto/)\n",
    "<br> [RSEM](http://deweylab.github.io/RSEM/)\n",
    "\n",
    "Here, we will use Salmon for read mapping. Salmon take as input `fastq` and a reference transcriptome and produces quantification files that end with .sf. \n",
    "\n",
    "A short tutorial on how to use Salmon can be found [here](https://combine-lab.github.io/salmon/getting_started/). We will not run this program on CoCalc due to memory constraints, so we have already provided you with Salmon output on two FASTQ files.\n",
    "\n",
    "As an example, we will use the airways dataset that contains RNA-Seq data of four human airway smooth muscle cell lines, n=2  treated and n=2 untreated with dexamethasone. \n",
    "\n",
    "Under the directory `/quants`, you will find the output of Salmon on two samples, the name of each directory corresponds to the sample name, the file quants.sf.gz contains the mapping information that we will load to our R workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To load Salmon mappings into R we will use the library `tximeta`, this library not only provides tool to loading and process of transcript mapping data, but also provides automatic annotation of metadata for commonly used transcriptomes.\n",
    "\n",
    "**Q7.** Execute the code below to load the library and a table containing meta data associated with the two samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tximeta)\n",
    "library(SummarizedExperiment)\n",
    "coldata <- read.csv(\"full_table.csv\", row.names=1, stringsAsFactors=FALSE)\n",
    "coldata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to load this data using `tximeta`, our `coldata` table will need to contain two additional columns: \n",
    "   \n",
    "   `names`: for the name of the sample and \n",
    "   \n",
    "   `files`: with the complete path to each `quants.sf.gz` file.\n",
    "\n",
    "**Q8.** Run the code below to add these columns, take a minute to understand how the path to each file is generated. If needed, run the `file.path()` command separatly and take a look at the out it produces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coldata$names = coldata$Run\n",
    "coldata$files = file.path('quants' , coldata$names, \"quant.sf.gz\")\n",
    "coldata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wanted to run this on your own in your computational space, you could use:\n",
    "\n",
    "`se <- tximeta(coldata)`\n",
    "\n",
    "\n",
    "This would format the object and identify and download the annotation for the transcriptome index used for mapping automatically (and store in a variable called `se`).\n",
    "\n",
    "**DO NOT RUN THIS ON COCALC.** Unfortunately, the job to generate this object is memory intensive, so not able to be run on CoCalc.\n",
    "\n",
    "As a result, we have provided this object to you which you can load into R!\n",
    "\n",
    "**Q9.** Execute the command below to load the data and create a new variable `se`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load(file=\"gse_se.RData\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have just loaded a SummarizedExperiment (SE) object. This is an important data structure that is used as a basic structure in which RNA-Seq data is stored in R. \n",
    "\n",
    "You can access the  objects by their variable names `se` and `gse`.\n",
    "\n",
    "The structure is depicted in the figure below: <br>\n",
    "<img src=\"files/SEstructure.png\" width=\"400\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`coldata` conatins the data about the samples which we have provided to the tximeta function.\n",
    "\n",
    "`rowRanges` contains information about each gene/transcripts, this data was downloaded automatically because we used a standard transcriptome assembly. \n",
    "\n",
    "`assays` is part of the SE object and contains the actual counts. Note that there can be more than one assay associated with different processing levels, e.g. normalized and non-normalized counts.\n",
    "\n",
    "### Please review sections one and two of this [vignette](https://bioconductor.org/packages/release/bioc/vignettes/SummarizedExperiment/inst/doc/SummarizedExperiment.html) to familiarize yourself with the structure of the SummarizedExperiment object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10.** Now:\n",
    "\n",
    "- Use `dim()` to obtain the dimensions of your current SE object and report how many transcripts are quantified.\n",
    "- Use `head()` to get a summary of `se`.\n",
    "\n",
    "**Provide and Execute your code below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q11.** You will notice that there are three assays, use the code below to list their names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assayNames(se)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three assays correspond to the output from the Salmon aligner:\n",
    "\n",
    "`counts` is the non-normalized read count per transcript.\n",
    "\n",
    "`abundance` is the estimated relative abundance of this transcript in units of TPM (transcripts per million).\n",
    "\n",
    "`length` is the length of the transcript (effective length, see below).\n",
    "\n",
    "**Q12.** Take a look at these assays using the command \n",
    "\n",
    "`head(assays(se)$count)`\n",
    "\n",
    "Next,\n",
    "\n",
    "- perform the above with `abundance` and `length`.\n",
    "- summarize the information about each transcript using `rowRanges(se)`\n",
    "\n",
    "Note that transcript length is not same for the two samples!\n",
    "\n",
    "The reason for this is that it is harder to capture the ends of the transcripts, and the Salmon algorithm estimates an *effective* length for each sample separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, because we are interested in gene and not transcript information, we will need to summarize transcript data to genes.\n",
    "\n",
    "If you wanted to run this on your own in your computational space, you could use:\n",
    "\n",
    "`gse <- summarizeToGene(se)`\n",
    "\n",
    "This would format the object and identify and download the annotation for the transcriptome index used for mapping automatically (and store in a variable called `gse`).\n",
    "\n",
    "**DO NOT RUN THIS ON COCALC.** Unfortunately, the job to generate this object is memory intensive, so not able to be run on CoCalc.\n",
    "\n",
    "\n",
    "\n",
    "As a result, we have also provided you this object (which you already loaded into R in **Q9**) called `gse`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q13.** Now:\n",
    "\n",
    "- Use `dim()` to obtain the dimensions of the `gse` object and report how many genes are quantified.\n",
    "- Use `head()` to get a summary of `gse`\n",
    "\n",
    "Note that the dimentions are now much smaller because transcript isoforms have been aggregated to single genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some addtional functions that can be used to explore the gene \"meta data\".\n",
    "\n",
    "**Q14.** Run the code below to access gene sequence information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowRanges(gse)\n",
    "seqinfo(rowRanges(gse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As was in the case of the array gene expression analysis, our next step(s) will be to \n",
    "\n",
    "- Normalize the data\n",
    "- Perform a statistical test to look for genes that are differently expressed between treatment and controls\n",
    "\n",
    "This will be the focus of the next session. \n",
    "\n",
    "To perform statistical testing, we do need to consider how the data is distributed in order to select the proper statistical test to measure expression differences between treatment and control. \n",
    "\n",
    "For example, we could use a t-test if expression levels are approximately normally distributed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15.** Create a histogram of the count assay matrix, use a log10 scale. \n",
    "\n",
    "**Provide and Execute your code below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is close, but not *quite* a normal distribution. \n",
    "\n",
    "It turns out that gene expression count data is [better](http://bridgeslab.sph.umich.edu/posts/why-do-we-use-the-negative-binomial-distribution-for-rnaseq) [modeled](https://bioramble.wordpress.com/2016/01/30/why-sequencing-data-is-modeled-as-negative-binomial/) using the [Negative Binomial Distribution](https://stattrek.com/probability-distributions/negative-binomial.aspx). \n",
    "\n",
    "We will cover this in the next session!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final note. Recall the class session on the problem multiple hypothesis testing and correction we could consider to correct for this. \n",
    "\n",
    "**Q16.** What correction to adjust for multiple testing would you propose to apply to this experiment? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
