{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook - ATAC-seq and scATAC-seq (in-class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We thank the ENCODE consortium as well as Satija and Stuart team for their software and package tutorials, from which much of the material below is adapted. We thank the Epigenomics Workshop 2024 for posting educational materials online, which were also adapted in creating this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [[Important!!]] Instruction for running this notebook on Cocalc:\n",
    "Please follow the instructions below to configure your own environment to run this notebook. \n",
    "\n",
    "1. In the side bar, Find the \"Settings\" button, and click the triangle button next to it.\n",
    "2. Under the \"Control\" drop-down manu, change the Software environment to \"2024-02-07\", then save changes. \n",
    "3. Open a Linux Terminal.\n",
    "4. Run the following command in UNIX (at the prompt `$>`):\n",
    "\n",
    "    `$> mkdir ~/Rlibs`\n",
    "\n",
    "\n",
    "5. Start an R session from the UNIX command line (at the prompt `$>`):\n",
    "\n",
    "    `$> R`\n",
    "    \n",
    "    \n",
    "6. Type the following commands sequentially (each line one at a time, **not** copying and running the entire block of commands all at once!). Always **skip** any software updates by hitting \"enter\" if/when prompted.\n",
    " \n",
    "    `.libPaths(\"~/Rlibs\")`\n",
    "    \n",
    "    `require(devtools)`\n",
    "    \n",
    "    `install_version(\"SeuratObject\", version=\"5.0.1\")`\n",
    "    \n",
    "    `install_version(\"Signac\", version=\"1.13.0\")`\n",
    "    \n",
    "    `install.packages(\"irlba\")`\n",
    "    \n",
    "    `devtools::install_github(\"immunogenomics/presto\")`\n",
    "    \n",
    "    `BiocManager::install(\"EnsDb.Hsapiens.v86\")`\n",
    "    \n",
    " \n",
    "7. You can quit the R session via the `q()` function. This will return you to the UNIX command line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading packages\n",
    "\n",
    "Now, let's return to the notebook and load libraries that we have installed to check that the setup is working.\n",
    "\n",
    "First, run the cell below to add the local directory where libraries were installed to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".libPaths(\"~/Rlibs\")\n",
    ".libPaths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's load our libraries in two groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# run this\n",
    "library(Seurat)\n",
    "library(Signac)\n",
    "packageVersion(\"Seurat\")\n",
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now run this\n",
    "library(biovizBase)\n",
    "library(EnsDb.Hsapiens.v86)\n",
    "library(patchwork)\n",
    "library(\"presto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run this to set up for annotations\n",
    "library(AnnotationHub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run this library to set up enrichment analyses\n",
    "library(clusterProfiler)\n",
    "library(org.Hs.eg.db)\n",
    "library(enrichplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives of this notebook\n",
    "\n",
    "The objective of this notebook is to get students familiarize with data analysis on bulk and single-cell ATAC-seq data. This notebook will guide students through the steps of quality control, clustering, exploratory data analysis, and differential accessibility analysis. By the end of this process, we aim to uncover insights into the chromatin accessibility landscape across different conditions or cell types, and be able to process both public and primary datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup pipelines bulk ATAC-seq\n",
    "\n",
    "The ENCODE consortium provides a very useful tool for analyzing the bulk ATAC-seq data. Please take a look at their workflow, and answer Q1. https://www.encodeproject.org/pipelines/ENCPL787FUN/ (we recommend opening the website using safari as you may encounter display issues with Chrome)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. What is the input and output of the pipeline? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the ENCODE pipeline, a `.json` input file is required. All the experimental summary information, `.fastq` file location, and R1 and R2 read file locations should be provided in this file in order for the pipeline to recognize. Here, we will not actually run the whole pipeline, but we will edit the following `.json` file to mimic what we will need to do in running the pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.** Instruction for editing the input `.json` file can be found here: https://github.com/ENCODE-DCC/atac-seq-pipeline/blob/master/docs/input_short.md  Please read the instruction and edit the `.json` file in the text block below, with the information provided here:\n",
    "\n",
    "1. The data are collected from mouse liver\n",
    "2. You don't know the adapter, so you want the algorithm to automatically detect the adapter\n",
    "\n",
    "In your analysis, don't forget to double check the input `.fastq` files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "    \"atac.title\" : \"Example (paired end)\",\n",
    "    \"atac.description\" : \"This is a template input JSON for paired ended sample.\",\n",
    "\n",
    "    \"atac.pipeline_type\" : \"atac\",\n",
    "    \"atac.align_only\" : false,\n",
    "    \"atac.true_rep_only\" : false,\n",
    "\n",
    "    \"atac.genome_tsv\" : \"/path_to_genome_data/hg38/hg38.tsv\",\n",
    "\n",
    "    \"atac.paired_end\" : true,\n",
    "\n",
    "    \"atac.fastqs_rep1_R1\" : [ \"rep1_R1_L1.fastq.gz\", \"rep1_R1_L2.fastq.gz\", \"rep1_R1_L3.fastq.gz\" ],\n",
    "    \"atac.fastqs_rep1_R2\" : [ \"rep1_R2_L1.fastq.gz\", \"rep1_R2_L2.fastq.gz\", \"rep1_R2_L3.fastq.gz\" ],\n",
    "    \"atac.fastqs_rep2_R1\" : [ \"rep2_R1_L1.fastq.gz\", \"rep2_R1_L2.fastq.gz\" ],\n",
    "    \"atac.fastqs_rep2_R2\" : [ \"rep2_R2_L1.fastq.gz\", \"rep2_R2_L2.fastq.gz\" ],\n",
    "\n",
    "    \"atac.auto_detect_adapter\" : false,\n",
    "    \"atac.adapter\" : \"AATTCCGG\",\n",
    "    \"atac.adapters_rep1_R1\" : [ \"AATTCCGG\", \"AATTCCGG\", \"AATTCCGG\" ],\n",
    "    \"atac.adapters_rep1_R2\" : [ \"AATTCCGG\", \"AATTCCGG\" ],\n",
    "    \"atac.adapters_rep2_R1\" : [ \"AATTCCGG\", \"AATTCCGG\", \"AATTCCGG\" ],\n",
    "    \"atac.adapters_rep2_R2\" : [ \"AATTCCGG\", \"AATTCCGG\" ],\n",
    "\n",
    "    \"atac.multimapping\" : 4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have this .json file, you can obtain a pipeline which runs end-to-end QC and processing of ATAC-Seq data, which you can run on a computer cluster:\n",
    "\n",
    "`https://github.com/ENCODE-DCC/atac-seq-pipeline`\n",
    "\n",
    "We provide this for you here as many of you may end up workign with bulk ATAC-Seq data in your careers. You can go to this github page, get this pipeline installed on your local cluster (perhaps with the help of systems admins!), and then use the .json template you created above to execute the pipeline.\n",
    "\n",
    "For the purposes of more extensive in-class work, we'll turn now to setup for performing analysis of scATAC-Seq data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup -- scATAC-seq\n",
    "\n",
    "Just like for scRNA-seq, many tools have been developed for the analysis of scATAC-seq data. These packages include `Signac`, `ArchR`, `snapATAC (v1)` in **R** and `snapATAC (v2)`, `EpiScanpy` in **Python**. Since we have used `Seurat` for analyzing scRNA-seq data, we will use `Signac` (developed by the same lab) for the scATAC-seq data analysis. \n",
    "\n",
    "Just like `Seurat`, `Signac` have many useful vigenettes as well: https://stuartlab.org/signac/ \n",
    "\n",
    "Here, we will be analyzing a single-cell ATAC-seq dataset collected from Human PBMC by 10x Genomics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading scATAC-seq data\n",
    "From the `CellRanger-ATAC` pipeline, four files will be used for constructing the `Signac` object, they are:\n",
    "\n",
    "- A count file. The rows are regions (peaks) and the colums are cells. Each entry i,j is the number of reads mapping to region i in cell j. In this assignment, our file is \n",
    "\n",
    "`atac_pbmc_500_nextgem_filtered_peak_bc_matrix.h5`\n",
    "\n",
    "\n",
    "- A meta data file, with some overall statistics for each cell. In this assignment, our file is \n",
    "\n",
    "`atac_pbmc_500_nextgem_singlecell.csv`\n",
    "\n",
    "\n",
    "- A fragment file, with information on all sequenced fragments (where it maps to the genome, which cell barcode is associated and how many PCR duplicates were found). In this assignment, our file is \n",
    "\n",
    "`atac_pbmc_500_nextgem_fragments_sub.tsv.gz`\n",
    "\n",
    "\n",
    "- An index file connected to the fragment file. This is like an index file for a bam file, to make it possible to quickly find fragments for a certain genomic region, without having to search the entire file. In this assignment, our file called \n",
    "\n",
    "`atac_pbmc_500_nextgem_fragments_sub.tsv.gz.tbi`\n",
    "\n",
    "\n",
    "(Note that you won't specify this file, but is required. We pre-created this file for you using `tabix` in UNIX.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Seurat object\n",
    "\n",
    "Using the above files, edit the code below to specify the file names in the places indicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "counts <- Read10X_h5(filename = \"\") ##Specify the count file here\n",
    "\n",
    "metadata <- read.csv(\n",
    "  file = \"\", ##Specify the meta data file here\n",
    "  header = TRUE,\n",
    "  row.names = 1\n",
    ")\n",
    "\n",
    "chrom_assay <- CreateChromatinAssay(\n",
    "  counts = counts,\n",
    "  sep = c(\":\", \"-\"),\n",
    "  fragments = \"\", ##Specify the fragment file here\n",
    "  min.cells = 10,\n",
    "  min.features = 200\n",
    ")\n",
    "\n",
    "pbmc <- CreateSeuratObject(\n",
    "  counts = chrom_assay,\n",
    "  assay = \"peaks\",\n",
    "  meta.data = metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's add gene annotations. \n",
    "\n",
    "For this, we will take advantage of precomputed annotations which you can search for at `AnnotationHub`.\n",
    "\n",
    "This will allow downstream functions to pull the gene annotation information directly from the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub <- AnnotationHub()\n",
    "query(hub, c(\"ensdb\", \"homo sapiens\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, you can see a list of many annotations you could choose from, and from many species. For example, you *could* replace `homo sapiens` in the above with mouse (`mus musculus`) or zebrafish (`danio rerio`) and also obain annotation sets. \n",
    "\n",
    "But here, we are working with human data, so let's select a recent annotated genome data base from humans (version 111). As you can see, this recent database corresponds to the database ID `AH116291`. Let's store that annotation in an object called `ensdb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query(hub, c(\"ensdb\",\"homo sapiens\", \"111\"))\n",
    "ensdb <- hub[[\"AH116291\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# # extract gene annotations from EnsDb\n",
    "annotations <- GetGRangesFromEnsDb(ensdb = ensdb)\n",
    "\n",
    "# # change to UCSC style since the data was mapped to hg38\n",
    "seqlevels(annotations) <- paste0('chr', seqlevels(annotations))\n",
    "genome(annotations) <- \"hg38\"\n",
    "\n",
    "# # add the gene information to the object\n",
    "Annotation(pbmc) <- annotations\n",
    "Annotation(pbmc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing QC metrics \n",
    "\n",
    "We have introduced these common QC metrics in our prelab notebook. Please refer back to that notebook or the Signac website (https://stuartlab.org/signac/articles/pbmc_vignette) for more information. \n",
    "\n",
    "The enrichment of Tn5 integration events at transcriptional start sites (TSSs) can also be an important quality control metric to assess the targeting of Tn5 in ATAC-seq experiments. The ENCODE consortium defined a TSS enrichment score as the number of Tn5 integration site around the TSS normalized to the number of Tn5 integration sites in flanking regions. See the ENCODE documentation for more information about the TSS enrichment score (https://www.encodeproject.org/data-standards/terms/). \n",
    "\n",
    "We can calculate the TSS enrichment score for each cell using the `TSSEnrichment()` function in Signac."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# compute nucleosome signal score per cell\n",
    "pbmc <- NucleosomeSignal(object = pbmc)\n",
    "\n",
    "# # compute TSS enrichment score per cell\n",
    "pbmc <- TSSEnrichment(object = pbmc)\n",
    "\n",
    "# add fraction of reads in peaks\n",
    "pbmc$pct_reads_in_peaks <- pbmc$peak_region_fragments / pbmc$passed_filters * 100\n",
    "\n",
    "# # add blacklist ratio\n",
    "pbmc$blacklist_ratio <- FractionCountsInRegion(\n",
    "   object = pbmc, \n",
    "   assay = 'peaks',\n",
    "   regions = blacklist_hg38_unified\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the relationship between variables stored in our object (`pmbc`), for example, using `DensityScatter`. This can be helpful in deciding suitable cutoff values for different QC metrics that we have calculated. For example, let's look at the relationship between read count an TSS.enrichment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DensityScatter(pbmc, x = 'nCount_peaks', y = 'TSS.enrichment', log_x = TRUE, quantiles = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data here are are more *sparse* that what you would see in a typical experiment, as we have created a subset of data that you can work with within the CoCalc environment. However, what you can see is that there is a central density of data, with some outliers (high and low peak counts, for example). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, it is also help to look at the fragement length distribution, as we expect nucleosome positioning periodicity in the data. We can look at this using the `nucleosome signal`; let's look at characteristics for scores less than 4 and greater than 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "pbmc$nucleosome_group <- ifelse(pbmc$nucleosome_signal > 4, 'NS > 4', 'NS < 4')\n",
    "FragmentHistogram(object = pbmc, group.by = 'nucleosome_group')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot on the left shows that for NS < 4, we can see the periodicity we expect from a successful ATAC-Seq experiment. While hard to see on the right, there is a slight excess of mononucleosomal / nucleosome-free ratio (this holds in the larger data sets). as such, we may want to remove these downstream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot distribution of each QC metric separately via a violin plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "VlnPlot(\n",
    "  object = pbmc,\n",
    "  features = c('nCount_peaks', 'TSS.enrichment', 'blacklist_ratio', 'nucleosome_signal', 'pct_reads_in_peaks'),\n",
    "  pt.size = 0.1,\n",
    "  ncol = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering based on QC metric\n",
    "\n",
    "Here, we will set some initial QC filters, to focus on a subset of peaks with the following properties:\n",
    "\n",
    "- read count in peaks greater than 9,000 (i.e., insist on a minimum read depth in a peak)\n",
    "- read count in peak less than 100,000 (i.e., if a peak has too much depth, exclude)\n",
    "- minimum fraction of read coverage in peaks (i.e., 40%)\n",
    "- blacklist ratio less than 1% (i.e., 0.01)\n",
    "- Nucleosome signal less than 4\n",
    "- TSS enrichemnt greater than 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "pbmc <- subset(\n",
    "  x = pbmc,\n",
    "  subset = nCount_peaks > 9000 &\n",
    "    nCount_peaks < 100000 &\n",
    "    pct_reads_in_peaks > 40 &\n",
    "    blacklist_ratio < 0.01 &\n",
    "    nucleosome_signal < 4 &\n",
    "    TSS.enrichment > 4\n",
    ")\n",
    "pbmc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Normalization and linear dimensional reduction\n",
    "\n",
    "Next, as described in the prelab, we will normalize the subset of peaks we selected above using Term Frequency-Inverse Document Frequency (TF-IDF), and then perform dimensionality reduction for interpretive purposes using singular value decomposition (SVD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "pbmc <- RunTFIDF(pbmc)\n",
    "pbmc <- FindTopFeatures(pbmc, min.cutoff = 'q0')\n",
    "pbmc <- RunSVD(pbmc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first LSI component often captures sequencing depth (technical variation) rather than biological variation. If this is the case, the component should be removed from downstream analysis. We can assess the correlation between each LSI component and sequencing depth using the DepthCor() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "DepthCor(pbmc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see there is a very strong (negative) correlation between the first LSI component and the total number of counts for the cell, so we will perform downstream steps without this component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-linear dimension reduction and clustering\n",
    "Now that the cells are embedded in a low-dimensional space, we can use methods commonly applied for the analysis of scRNA-seq data to perform graph-based clustering, and non-linear dimension reduction for visualization. The functions `RunUMAP()`, `FindNeighbors()`, and `FindClusters()` all come from the Seurat package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "pbmc <- RunUMAP(object = pbmc, reduction = 'lsi', dims = 2:30)\n",
    "pbmc <- FindNeighbors(object = pbmc, reduction = 'lsi', dims = 2:30)\n",
    "pbmc <- FindClusters(object = pbmc, verbose = FALSE, algorithm = 3)\n",
    "DimPlot(object = pbmc, label = TRUE) + NoLegend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: In this notebook, we will skip the integration with scRNA-seq part. Based on various benchmark efforts, the integration between unmatched scRNA-seq and scATAC-seq can be very challenging. We recommend running this type of analysis with caution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find differentially accessible peaks between clusters\n",
    "To find differentially accessible regions between clusters of cells, we can perform a differential accessibility (DA) test. A simple approach is to perform a Wilcoxon rank sum test, and the presto package has implemented an extremely fast Wilcoxon test that can be run on a Seurat object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "DefaultAssay(pbmc) <- 'peaks'\n",
    "\n",
    "da_peaks <- FindMarkers(\n",
    "  object = pbmc,\n",
    "  ident.1 = c(\"0\"), \n",
    "  ident.2 = c(\"1\"), \n",
    "  test.use = 'wilcox',\n",
    "  min.pct = 0.1\n",
    ")\n",
    "\n",
    "head(da_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "plot1 <- VlnPlot(\n",
    "  object = pbmc,\n",
    "  features = rownames(da_peaks)[1],\n",
    "  pt.size = 0.1,\n",
    "  idents = c(\"0\",\"1\")\n",
    ")\n",
    "plot2 <- FeaturePlot(\n",
    "  object = pbmc,\n",
    "  features = rownames(da_peaks)[1],\n",
    "  pt.size = 0.1\n",
    ")\n",
    "\n",
    "plot1 | plot2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, Let's look at the annotations for some of these significant peaks. let's look at those where cluster 0 is open, relative to cluster 1, and vice-versa where cluster 1 is open, realtive to cluster 0.\n",
    "\n",
    "Let us also filter this by significance of association as well as the log fold change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_c0 <- rownames(da_peaks[da_peaks$avg_log2FC > 3 & da_peaks$p_val_adj < 1e-5, ])\n",
    "open_c1 <- rownames(da_peaks[da_peaks$avg_log2FC < -3 & da_peaks$p_val_adj < 1e-5, ])\n",
    "\n",
    "closest_genes_c0 <- ClosestFeature(pbmc, regions = open_c0)\n",
    "closest_genes_c1 <- ClosestFeature(pbmc, regions = open_c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gene Ontology Enrichment Analysis\n",
    "Just like in the proteomics module, we can also perform enrichment analyses for our peaks using the genes TSS that is the nearest to our peaks. We have done this below for c0 and c1 clusters -- but you could do comparisons with different clusters with edits to the above code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd0_ego <- enrichGO(gene = closest_genes_c0$gene_id,\n",
    "                keyType = \"ENSEMBL\",\n",
    "                OrgDb = org.Hs.eg.db,\n",
    "                ont = \"BP\",\n",
    "                pAdjustMethod = \"BH\",\n",
    "                pvalueCutoff = 0.05,\n",
    "                qvalueCutoff = 0.05,\n",
    "                readable = TRUE)\n",
    "\n",
    "barplot(cd0_ego,showCategory = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd1_ego <- enrichGO(gene = closest_genes_c1$gene_id,\n",
    "                keyType = \"ENSEMBL\",\n",
    "                OrgDb = org.Hs.eg.db,\n",
    "                ont = \"BP\",\n",
    "                pAdjustMethod = \"BH\",\n",
    "                pvalueCutoff = 0.05,\n",
    "                qvalueCutoff = 0.05,\n",
    "                readable = TRUE)\n",
    "\n",
    "barplot(cd1_ego,showCategory = 20)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
