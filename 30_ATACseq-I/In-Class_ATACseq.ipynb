{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook - ATAC-seq and scATAC-seq (in-class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We thank the ENCODE consortium as well as Satija and Stuart team for their software and package tutorials, from which much of the material below is adapted. We thank the Epigenomics Workshop 2024 for posting educational materials online, which were also adapted in creating this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [[Important!!]] Instruction for running this notebook on Cocalc:\n",
    "Please follow the instructions below to configure your own environment to run this notebook. \n",
    "\n",
    "1. In the side bar, Find the \"Settings\" button, and click the triangle butten next to it.\n",
    "2. Under the \"Control\" drop-down manu, change the Software environment to \"2024-02-07\", then save changes. \n",
    "3. Open a Linux Terminal\n",
    "4. Type “R” to start an R session\n",
    "5. Type the following commands sequentially. Always **skip** any software updates\n",
    " - require(devtools)\n",
    " - install_version(“SeuratObject”, version=“5.0.1”)\n",
    " - install_version(“Signac”, version=“1.13.0”)\n",
    " - install.packages(“irlba”)\n",
    " - devtools::install_github(‘immunogenomics/presto’)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives of this notebook\n",
    "\n",
    "The objective of this notebook is to get students familiarize with data analysis on bulk and single-cell ATAC-seq data. This notebook will guide students through the steps of quality control, clustering, exploratory data analysis, and differential accessibility analysis. By the end of this process, we aim to uncover insights into the chromatin accessibility landscape across different conditions or cell types, and be able to process both public and primary datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup -- ATAC-seq\n",
    "\n",
    "The ENCODE consortium provides a very useful tool for analyzing the bulk ATAC-seq data. Please take a look at their workflow, and answer Q1. https://www.encodeproject.org/pipelines/ENCPL787FUN/ (we recommend opening the website using safari as you may encounter display issues with Chrome)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. What is the input and output of the pipeline? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the ENCODE pipeline, a `.json` input file is required. All the experimental summary information, `.fastq` file location, and R1 and R2 read file locations should be provided in this file in order for the pipeline to recognize. Here, we will not actually run the whole pipeline, but we will edit the following `.json` file to mimic what we will need to do in running the pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.** Instruction for editing the input `.json` file can be found here: https://github.com/ENCODE-DCC/atac-seq-pipeline/blob/master/docs/input_short.md  Please read the instruction and edit the `.json` file in the text block below, with the information provided here:\n",
    "\n",
    "1. The data are collected from mouse liver\n",
    "2. You don't know the adapter, so you want the algorithm to automatically detect the adapter\n",
    "\n",
    "In your analysis, don't forget to double check the input `.fastq` files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "    \"atac.title\" : \"Example (paired end)\",\n",
    "    \"atac.description\" : \"This is a template input JSON for paired ended sample.\",\n",
    "\n",
    "    \"atac.pipeline_type\" : \"atac\",\n",
    "    \"atac.align_only\" : false,\n",
    "    \"atac.true_rep_only\" : false,\n",
    "\n",
    "    \"atac.genome_tsv\" : \"/path_to_genome_data/hg38/hg38.tsv\",\n",
    "\n",
    "    \"atac.paired_end\" : true,\n",
    "\n",
    "    \"atac.fastqs_rep1_R1\" : [ \"rep1_R1_L1.fastq.gz\", \"rep1_R1_L2.fastq.gz\", \"rep1_R1_L3.fastq.gz\" ],\n",
    "    \"atac.fastqs_rep1_R2\" : [ \"rep1_R2_L1.fastq.gz\", \"rep1_R2_L2.fastq.gz\", \"rep1_R2_L3.fastq.gz\" ],\n",
    "    \"atac.fastqs_rep2_R1\" : [ \"rep2_R1_L1.fastq.gz\", \"rep2_R1_L2.fastq.gz\" ],\n",
    "    \"atac.fastqs_rep2_R2\" : [ \"rep2_R2_L1.fastq.gz\", \"rep2_R2_L2.fastq.gz\" ],\n",
    "\n",
    "    \"atac.auto_detect_adapter\" : false,\n",
    "    \"atac.adapter\" : \"AATTCCGG\",\n",
    "    \"atac.adapters_rep1_R1\" : [ \"AATTCCGG\", \"AATTCCGG\", \"AATTCCGG\" ],\n",
    "    \"atac.adapters_rep1_R2\" : [ \"AATTCCGG\", \"AATTCCGG\" ],\n",
    "    \"atac.adapters_rep2_R1\" : [ \"AATTCCGG\", \"AATTCCGG\", \"AATTCCGG\" ],\n",
    "    \"atac.adapters_rep2_R2\" : [ \"AATTCCGG\", \"AATTCCGG\" ],\n",
    "\n",
    "    \"atac.multimapping\" : 4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup -- scATAC-seq\n",
    "\n",
    "Just like for scRNA-seq, many tools have been developed for the analysis of scATAC-seq data. These packages include `Signac`, `ArchR`, `snapATAC (v1)` in **R** and `snapATAC (v2)`, `EpiScanpy` in **Python**. Since we have used `Seurat` for analyzing scRNA-seq data, we will use `Signac` (developed by the same lab) for the scATAC-seq data analysis. \n",
    "\n",
    "Just like `Seurat`, `Signac` have many useful vigenettes as well: https://stuartlab.org/signac/ \n",
    "\n",
    "Here, we will be analyzing a single-cell ATAC-seq dataset collected from Human PBMC by 10x Genomics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(Seurat)\n",
    "library(Signac)\n",
    "packageVersion(\"Seurat\")\n",
    "library(tidyverse)\n",
    "# library(EnsDb.Hsapiens.v86)\n",
    "library(ggplot2)\n",
    "library(patchwork)\n",
    "library(\"presto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading scATAC-seq data\n",
    "From the `CellRanger-ATAC` pipeline, four files will be used for constructing the `Signac` object, they are:\n",
    "\n",
    "- A count file. The rows are regions (peaks) and the colums are cells. Each entry i,j is the number of reads mapping to region i in cell j. In this assignment, our file is `atac_pbmc_500_nextgem_filtered_peak_bc_matrix.h5`.\n",
    "\n",
    "\n",
    "- A meta data file, with some overall statistics for each cell. In this assignment, our file is `atac_pbmc_500_nextgem_singlecell.csv`.\n",
    "\n",
    "\n",
    "- A fragment file, with information on all sequenced fragments (where it maps to the genome, which cell barcode is associated and how many PCR duplicates were found). In this assignment, our file is `atac_pbmc_500_nextgem_fragments_sub.tsv.gz` \n",
    "\n",
    "\n",
    "- An index file connected to the fragment file. This is like an index file for a bam file, to make it possible to quickly find fragments for a certain genomic region, without having to search the entire file. In this assignment, our file called `atac_pbmc_500_nextgem_fragments_sub.tsv.gz.tbi`. (Note that you won't specify this file, but is required. We pre-created this file for you using `tabix` in UNIX.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Seurat object\n",
    "\n",
    "Using the above files, edit the code below to specify the file names in the places indicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "counts <- Read10X_h5(filename = \"\") ##Specify the count file here\n",
    "\n",
    "metadata <- read.csv(\n",
    "  file = \"\", ##Specify the meta data file here\n",
    "  header = TRUE,\n",
    "  row.names = 1\n",
    ")\n",
    "\n",
    "chrom_assay <- CreateChromatinAssay(\n",
    "  counts = counts,\n",
    "  sep = c(\":\", \"-\"),\n",
    "  fragments = \"\", ##Specify the fragment file here\n",
    "  min.cells = 10,\n",
    "  min.features = 200\n",
    ")\n",
    "\n",
    "pbmc <- CreateSeuratObject(\n",
    "  counts = chrom_assay,\n",
    "  assay = \"peaks\",\n",
    "  meta.data = metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add gene annotations. This will allow downstream functions to pull the gene annotation information directly from the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# # the coCalc system has trouble installing the lastest annotation, So let us skip this step in class \n",
    "\n",
    "# # extract gene annotations from EnsDb\n",
    "# annotations <- GetGRangesFromEnsDb(ensdb = ensdb_v86)\n",
    "\n",
    "# # change to UCSC style since the data was mapped to hg38\n",
    "# seqlevels(annotations) <- paste0('chr', seqlevels(annotations))\n",
    "# genome(annotations) <- \"hg38\"\n",
    "\n",
    "# # add the gene information to the object\n",
    "# Annotation(pbmc) <- annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing QC metrics \n",
    "We have introduced these common QC metrics in our prelab notebook. Please refer to that notebook or the Signac website (https://stuartlab.org/signac/articles/pbmc_vignette) for more information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# compute nucleosome signal score per cell\n",
    "pbmc <- NucleosomeSignal(object = pbmc)\n",
    "\n",
    "# # compute TSS enrichment score per cell\n",
    "# pbmc <- TSSEnrichment(object = pbmc)\n",
    "\n",
    "# add fraction of reads in peaks\n",
    "pbmc$pct_reads_in_peaks <- pbmc$peak_region_fragments / pbmc$passed_filters * 100\n",
    "\n",
    "# # add blacklist ratio\n",
    "# pbmc$blacklist_ratio <- FractionCountsInRegion(\n",
    "#   object = pbmc, \n",
    "#   assay = 'peaks',\n",
    "#   regions = blacklist_hg38_unified\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The enrichment of Tn5 integration events at transcriptional start sites (TSSs) can also be an important quality control metric to assess the targeting of Tn5 in ATAC-seq experiments. The ENCODE consortium defined a TSS enrichment score as the number of Tn5 integration site around the TSS normalized to the number of Tn5 integration sites in flanking regions. See the ENCODE documentation for more information about the TSS enrichment score (https://www.encodeproject.org/data-standards/terms/). We can calculate the TSS enrichment score for each cell using the TSSEnrichment() function in Signac."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "pbmc$nucleosome_group <- ifelse(pbmc$nucleosome_signal > 4, 'NS > 4', 'NS < 4')\n",
    "FragmentHistogram(object = pbmc, group.by = 'nucleosome_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "VlnPlot(\n",
    "  object = pbmc,\n",
    "  features = c('nCount_peaks', 'nucleosome_signal', 'pct_reads_in_peaks'),\n",
    "  pt.size = 0.1,\n",
    "  ncol = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering based on QC metric\n",
    "\n",
    "Here, we will set some initial QC filters, to focus on a subset of peaks with the following properties:\n",
    "\n",
    "- read count in peaks greater than 9,000 (i.e., insist on a minimum read depth in a peak)\n",
    "- read count in peak less than 100,000 (i.e., if a peak has too much depth, exclude)\n",
    "- minimum fraction of read coverage in peaks (i.e., 40%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "pbmc <- subset(\n",
    "  x = pbmc,\n",
    "  subset = nCount_peaks > 9000 &\n",
    "    nCount_peaks < 100000 &\n",
    "    pct_reads_in_peaks > 40 \n",
    ")\n",
    "pbmc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Normalization and linear dimensional reduction\n",
    "\n",
    "Next, as described in the prelab, we will normalize the subset of peaks we selected above using Term Frequency-Inverse Document Frequency (TF-IDF), and then perform dimensionality reduction for interpretive purposes using singular value decomposition (SVD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "pbmc <- RunTFIDF(pbmc)\n",
    "pbmc <- FindTopFeatures(pbmc, min.cutoff = 'q0')\n",
    "pbmc <- RunSVD(pbmc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first LSI component often captures sequencing depth (technical variation) rather than biological variation. If this is the case, the component should be removed from downstream analysis. We can assess the correlation between each LSI component and sequencing depth using the DepthCor() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "DepthCor(pbmc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see there is a very strong correlation between the first LSI component and the total number of counts for the cell, so we will perform downstream steps without this component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-linear dimension reduction and clustering\n",
    "Now that the cells are embedded in a low-dimensional space, we can use methods commonly applied for the analysis of scRNA-seq data to perform graph-based clustering, and non-linear dimension reduction for visualization. The functions `RunUMAP()`, `FindNeighbors()`, and `FindClusters()` all come from the Seurat package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "pbmc <- RunUMAP(object = pbmc, reduction = 'lsi', dims = 2:30)\n",
    "pbmc <- FindNeighbors(object = pbmc, reduction = 'lsi', dims = 2:30)\n",
    "pbmc <- FindClusters(object = pbmc, verbose = FALSE, algorithm = 3)\n",
    "DimPlot(object = pbmc, label = TRUE) + NoLegend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: In this notebook, we will skip the integration with scRNA-seq part. Based on various benchmark efforts, the integration between unmatched scRNA-seq and scATAC-seq can be very challenging. We recommend running this type of analysis with caution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find differentially accessible peaks between clusters\n",
    "To find differentially accessible regions between clusters of cells, we can perform a differential accessibility (DA) test. A simple approach is to perform a Wilcoxon rank sum test, and the presto package has implemented an extremely fast Wilcoxon test that can be run on a Seurat object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "DefaultAssay(pbmc) <- 'peaks'\n",
    "\n",
    "da_peaks <- FindMarkers(\n",
    "  object = pbmc,\n",
    "  ident.1 = c(\"0\"), \n",
    "  ident.2 = c(\"1\"), \n",
    "  test.use = 'wilcox',\n",
    "  min.pct = 0.1\n",
    ")\n",
    "\n",
    "head(da_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "plot1 <- VlnPlot(\n",
    "  object = pbmc,\n",
    "  features = rownames(da_peaks)[1],\n",
    "  pt.size = 0.1,\n",
    "  idents = c(\"0\",\"1\")\n",
    ")\n",
    "plot2 <- FeaturePlot(\n",
    "  object = pbmc,\n",
    "  features = rownames(da_peaks)[1],\n",
    "  pt.size = 0.1\n",
    ")\n",
    "\n",
    "plot1 | plot2"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
