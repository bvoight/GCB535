{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Game time 2 / ML 4 Prelab!\n",
    "\n",
    "We introduced you to this game in ML-III. Today we're going to go all in! Before class on Friday, make sure that you have a classifier for each disease (D1 and D2) that you feel performs the best of all of the classifiers that you've constructed and that you can estimate the accuracy for.\n",
    "\n",
    "To help you along, we've leveled you up to 500 examples of each! They're formatted just like the samples that you've already worked with, but they're all in one dataset (D1.csv and D2.csv).\n",
    "\n",
    "You should start with the code from last time. In the interests of recording your research steps, remember that whatever you try should be recorded and noted in the iPython notebook.\n",
    "\n",
    "Let's go ahead and load up the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
   ],
   "source": [
    "# numpy provides python tools to easily load comma separated files.\n",
    "import numpy as np\n",
    "\n",
    "# use numpy to load disease #1 data\n",
    "d1 = np.loadtxt(open(\"../31_Data_ML-IV/D1.csv\", \"rb\"), delimiter=\",\")\n",
    "\n",
    "# features are all rows for columns before 200\n",
    "# The canonical way to name this is that X is our matrix of\n",
    "# examples by features.\n",
    "X1 = d1[:,:200]\n",
    "\n",
    "# labels are in all rows at the 200th column\n",
    "# The canonical way to name this is that y is our vector of\n",
    "# labels.\n",
    "y1 = d1[:,200]\n",
    "\n",
    "# use numpy to load disease #2 data\n",
    "d2 = np.loadtxt(open(\"../31_Data_ML-IV/D2.csv\", \"rb\"), delimiter=\",\")\n",
    "\n",
    "# features are all rows for columns before 200\n",
    "X2 = d2[:,:200]\n",
    "# labels are in all rows at the 200th column\n",
    "y2 = d2[:,200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Random Seeds\n",
    "\n",
    "Sometimes we want to do things randomly... the same way over and over ([Groundhog Day](https://en.wikipedia.org/wiki/Groundhog_Day_(film)) style - after all, we're in Pennsylvania). Setting a random state lets us do this. The code below does not set a random state. Notice how the performance changes from run to run (run it a few times to see what happens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.521212121212\n"
     ]
    }
   ],
   "source": [
    "# Import the function to split our data:\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Split things into training and testing - let's have 30% of our data end up as testing\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=.33)\n",
    "\n",
    "# First, we need to import the classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Now we're going to get a decision tree classifier with the default parameters\n",
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "# The 'fit' syntax is the same\n",
    "classifier.fit(X1_train, y1_train)\n",
    "\n",
    "# As is the 'score' syntax\n",
    "train_score = classifier.score(X1_train, y1_train)\n",
    "test_score = classifier.score(X1_test, y1_test)\n",
    "\n",
    "\n",
    "print(\"Training Accuracy: \" + str(train_score))\n",
    "print(\"Testing Accuracy: \" + str(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "If we want to do the same thing each time, we can't. This is because the computer, at various points, needs to make up random numbers. This process is different each time. To make work reproducible, we may want to tell the computer to make up pseudorandom numbers predictably. We can do this by defining an initial state for our random number generator. `sklearn` usually does this through a function parameter called `random_state`. We could re-write the code above to use 42 as the random state. Once we do that (below), running the code will return the same result each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.50303030303\n"
     ]
    }
   ],
   "source": [
    "# Import the function to split our data:\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Split things into training and testing - let's have 30% of our data end up as testing\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=.33, random_state=42)\n",
    "\n",
    "# First, we need to import the classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Now we're going to get a decision tree classifier with the default parameters\n",
    "classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# The 'fit' syntax is the same\n",
    "classifier.fit(X1_train, y1_train)\n",
    "\n",
    "# As is the 'score' syntax\n",
    "train_score = classifier.score(X1_train, y1_train)\n",
    "test_score = classifier.score(X1_test, y1_test)\n",
    "\n",
    "\n",
    "print(\"Training Accuracy: \" + str(train_score))\n",
    "print(\"Testing Accuracy: \" + str(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Cross Validation\n",
    "\n",
    "Instead of using a separate training and testing partition, let's try out cross validation! A bit of light googling leads us to an [example in scikit learn](http://scikit-learn.org/0.17/modules/cross_validation.html#computing-cross-validated-metrics). This seems pretty handy. Let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.53 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "# Import the function to split our data:\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# First, we need to import the classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Now we're going to get a decision tree classifier with the default parameters\n",
    "classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Now we get the scores using this cross_val_score function\n",
    "# Note: We don't have to split the data with this approach.\n",
    "scores = cross_val_score(classifier, X1, y1)\n",
    "\n",
    "# This lets us calculate the accuracy + 2x standard deviation\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "# NOTE HOWEVER THAT WE DO NOT GET A CLASSIFIER BACK.\n",
    "# IF WE TRY TO RUN ANY OF THE CODE BELOW, WE WOULD\n",
    "# GET AN ERROR. IF WE WANT A CLASSIFIER INSTEAD OF\n",
    "# A PERFORMANCE ASSESSMENT, WE FIRST NEED TO FIT A\n",
    "# NEW ONE. WE COULD DO THIS OVER ALL THE DATA WITH\n",
    "# THE CODE:\n",
    "# classifier.fit(X1, y1)\n",
    "# YOU MAY USE THIS APPROACH FOR YOUR HOMEWORK\n",
    "# IF YOU USE CROSS VALIDATION TO ASSESS PERFORMANCE.\n",
    "\n",
    "# As is the 'score' syntax\n",
    "#train_score = classifier.score(X1_train, y1_train)\n",
    "#test_score = classifier.score(X1_test, y1_test)\n",
    "\n",
    "\n",
    "#print(\"Training Accuracy: \" + str(train_score))\n",
    "#print(\"Testing Accuracy: \" + str(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Be ready to use these handy new tools in class!\n",
    "\n",
    "_Q1_ This prelab question should be easy. What's been your favorite porition of the class thus far?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "_Q2_ What's your least favorite portion of the class thus far?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {
  },
  "kernelspec": {
   "display_name": "Python 2 (SageMath)",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "name": "ML_4.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}