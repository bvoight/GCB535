{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNAseq in a nutshell: From FASTQ files to differential expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last week we learned to quantify gene expression using arrays. This technology is still used in and has some advantages, but a much more widely used approach is measuring transcriptome abundance using high throughput sequencing.\n",
    "\n",
    "We will start this session by describing the structure and quality control measures used for fastq files. So, it is important that before you start the next two sessions, you understand how these files are generated as part of an RNAseq experimental pipeline. This is composed of two steps: library generation and high throughput sequencing. \n",
    "\n",
    "**Library generation:** RNA extracted from cells, model organism or tissue undergoes a procedure that converts the RNA into DNA while attempting to preserve the relative abundance of the different transcripts. It is important to remember that the total RNA in a cell is usually composed of mostly rRNA, which is usually depleted in the process of library prep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.** Take a look at figure 1a in the paper by Martin et al. which we provided for you on Canvas, when going from step 3 to 4 primers need to be added for the reverse transcriptase, usually two types are used, which primers would you used if you would like to make sure that you are sequencing only mRNA? (If you have never heard of cDNA before, look it up using google)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**High throughput sequencing:** Many technologies for massively parallel sequencing have been introduced over the years but definitely the most popular is the Illumina Sequencing-By-Synthesis (SBS) technology. The DNA fragments that undergo SBS are the ones depicted in step 7 in figure 1a mentioned above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.** Take a look at an introduction video by <a href=\"https://www.youtube.com/watch?v=fCd6B5HRaZ8&ab_channel=Illumina\" target=\"_blank\">Illumina on SBS</a>, Illumina sequencing has limitations on the size of the fragments that can be sequenced, too short or too long DNA fragments cannot be accurately sequenced. Based on this video, can you guess which step in the process is responsible for this limitation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that sequencing can be done using either single or paired-end reads, as the fragments are usually longer than the number of SBS cycles, a paired-end read would capture the full sequence of the fragment by sequencing the two ends and filling the middle part using the genomic of transcriptome reference sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of the FASTQ file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Illumina sequencing reads are stored in FASTQ files, in these files every read is stored as four rows as follows:\n",
    "\n",
    "* Line 1:\tSequence ID – will always start with @ and is a unique ID for the read, this line is important because in many cases each sequencing cluster will have more than one read (like paired end and sample barcode) which will need to be matched.\n",
    "* Line 2: Sequence – The actual sequence consisting of the four nucleotides and N in cases where the precise nucleotide could not have been determined.\n",
    "* Line 3: Quality ID – This line will always start with + which in some cases will be followed by and read quality score encoded in ASCII\n",
    "* Line 4: Quality score – Note that this line will contain the same number of characters as the sequence line, every letter encodes the quality of the corresponding nucleotide in the sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.** We have provided an example FASTQ file in your directory (sample.fastq), open a terminal and use your unix skills to look at the top lines of the file. What is the nucleotide sequence of the 10th read? How many reads total does this file contain? (remember that each read is four lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing FASTQ files quality and sequence composition with FASTQC \n",
    "\n",
    "FASTQC is an extremely convenient tool that you should use as your first step in testing the quality of an Illumina NGS run. FASTQC will analyze the nucleotide composition and sequence quality scores of your run and will output and html file for each `fastq` file summarizing the results. \n",
    "\n",
    "We have provided you a **very** small snippet of the full `fastq` file. Let's run it on this small bit of data. To do that,\n",
    "\n",
    "- Open up a UNIX terminal\n",
    "- Make directory named `tmp` in your main, home directory (e.g., `~/tmp`)\n",
    "- Run fastqc on the command line within your RNASeq-I working directory:\n",
    "       $> fastqc *.fastq\n",
    "       \n",
    "In general, this will analyze each `.fastq` file in your directory and summarize the quality measures for each file and ouptut to an html file. In this case, you only have one file to analyze (`sample.fastq`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4.** Open the resulting .html. How many reads were analyzed in this sample file?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full `fastq` file for these data is quite large (~24Gb!).\n",
    "\n",
    "So we have provided an example `fastqc` output file with the result of this tool run on the full data (`full_fastqc.html`).\n",
    "\n",
    "Open this file (you might need to download it to your computer) and explore the different summary statistics. Take a look at the per base sequence content, note the difference in nucleotide distribution at the begging of the reads compared to the middle of the reads. This is also reflected in the k-mer count. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5.** What is the 2nd most overrepresented kmer? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6.** What possible sources in the process of data generation could generate these k-mer count biases? (Hint: Think about library prep.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping of reads to the genome/transcriptome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to map the reads, representing RNA fragments, to a reference sequence library (as the genome) in order to convert the `fastq` files containing DNA fragments to a gene-based value associated with expression levels. \n",
    "\n",
    "In the early days of RNA-Seq, mapping was done mostly against the genome using aligners build to utilze \"short\" reads (150bp or less). Because reads are short - and do not capture a full transcript, this creates one additional layer of complexity - one will identify reads from varing splice isoforms that cross exon boundaries. (This is in contrast to other types of sequencing data generation, e.g. ChIP-Seq, which do not carry this complexity). \n",
    "\n",
    "One popular splicing aware aligner is [STAR](https://github.com/alexdobin/STAR) (Spliced Transcripts Alignment to Reference) which is considered a state-of-the-art aligner for this task.\n",
    "\n",
    "An alternative approach, which we will use here, is instead to map reads on a database of already assembled transcripts. The three leading algorithms for doing this are:\n",
    "\n",
    "[Salmon](https://combine-lab.github.io/salmon/)\n",
    "<br> [kallisto](https://pachterlab.github.io/kallisto/)\n",
    "<br> [RSEM](http://deweylab.github.io/RSEM/)\n",
    "\n",
    "Here, we will use Salmon for read mapping. Salmon take as input `fastq` and a reference transcriptome and produces quantification files that end with .sf. \n",
    "\n",
    "A short tutorial on how to use Salmon can be found [here](https://combine-lab.github.io/salmon/getting_started/). We will not run this program on CoCalc due to memory constraints, so we have already provided you with Salmon output on two FASTQ files.\n",
    "\n",
    "As an example, we will use the airways dataset that contains RNA-Seq data of four human airway smooth muscle cell lines, n=2  treated and n=2 untreated with dexamethasone. \n",
    "\n",
    "Under the directory `/quants`, you will find the output of Salmon on two samples, the name of each directory corresponds to the sample name, the file quants.sf.gz contains the mapping information that we will load to our R workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load Salmon mappings into R we will use the library `tximeta`, this library not only provides tool to loading and process of transcript mapping data, but also provides automatic annotation of metadata for commonly used transcriptomes. \n",
    "\n",
    "**Q7.** Execute the code below to load the library and a table containing meta data associated with the two samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tximeta)\n",
    "library(SummarizedExperiment)\n",
    "coldata <- read.csv(\"sample_table.csv\", row.names=1, stringsAsFactors=FALSE)\n",
    "coldata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to load this data using `tximeta`, our `coldata` table will need to contain two additional columns: \n",
    "   \n",
    "   `names`: for the name of the sample and \n",
    "   \n",
    "   `files`: with the complete path to each `quants.sf.gz` file.\n",
    "\n",
    "**Q8.** Run the code below to add these columns, take a minute to understand how the path to each file is generated. If needed, run the `file.path()` command separatly and take a look at the out it produces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coldata$names = coldata$Run\n",
    "coldata$files = file.path('quants' , coldata$names, \"quant.sf.gz\")\n",
    "coldata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9.** Now, use the command below to load the data. Note that the annotation for the transcriptome index that was used for mapping was automatically identified and loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se <- tximeta(coldata) ## BFV this needs to be adjusted / loading in .RData instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have just constructed a SummarizedExperiment (SE) object, this is an important data structure that is used as the basic data structure to store RNAseq data in R. The structure is depicted in the figure below <br>\n",
    "<img src=\"files/SEstructure.png\" width=\"400\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "colData conatins the data about the samples which we have provided to the tximeta function, rowRanges contains information about each gene/transcripts, this data was downloaded automatically because we used a standard transcriptome assembly. Assays part of the SE object countain the actual counts, there can be more than one assay associated with different processing levels, e.g. normalized and non normalized counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10.** Now:\n",
    "\n",
    "- Use `dim()` to obtain the dimensions of your current SE object and report how many transcripts are quantified.\n",
    "- Use `head()` to get a summary of `se`.\n",
    "\n",
    "**Provide and Execute your code below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q11.** You will notice that there are three assays, use the code below to list their names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assayNames(se)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three assays correspond to the output from the Salmon aligner, counts is non-normalized read counts per trasncript, abundance is TPM (transcripts per million) and length is the length of the transcript.\n",
    "\n",
    "**Q12.** Take a look at these assays using the command \n",
    "\n",
    "`head(assays(se)$count)`\n",
    "\n",
    "do this for abundance and length as well. Note that trascript length is not same for the two samples! The reason for this is that it is harder to capture the ends of the trasncripts and the Salmon algorithm estimates an effective length for each sample separatly. Also use the commant rowRanges(se) to get information about each transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, because we are interested in gene and not transcript information, we will need to summarize transcript data to genes.\n",
    "\n",
    "**Q11** Run the code below to generate gene level data, and then add a line that looks at the dimentions of your data using the commant dim. Note that the dimentions are now much smaller because transcript isoforms have been aggregated to single genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gse <- summarizeToGene(se)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some addtional functions that can be used to explore gene meta data.\n",
    "\n",
    "**Q12** Run the code below to access gene sequence information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowRanges(gse)\n",
    "seqinfo(rowRanges(gse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step will be to normalize the data and run statistical test to look for differential expressed genes, this will be the focus of the next session, but as the last step, recall class 23 about multiple hypothesis testing. We need to know how the data distributes in order to choose the right statistical test, for example we could have used a t-test if expression levels would have a normal distribution. \n",
    "\n",
    "**Q13** Make a histogram of the count assay matrix, use a log10 scale, does this look like a normal distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is close, but not really a normal distribution, apprently, gene expression data is best modeled using a negative binomial distribution, we will cover this in the next session!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
