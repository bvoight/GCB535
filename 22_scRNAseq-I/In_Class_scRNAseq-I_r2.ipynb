{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you to Alex's Lemonade Stand and the Seurat team for their teaching resources, from which much of the material below is adapted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scRNA-seq preprocessing and normalization\n",
    "\n",
    "It's always important to do rigorous preprocessing before analyzing our datasets, and more so for noisy scRNA-seq data. These steps are essential for producing interpretable results in the downstream analysis. In this class, weâ€™ll perform quality control and normalization of scRNA-seq count data with Seurat. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Many tools have been developed for the analysis of scRNA-seq data - we'll focus on one of the most widely used and well-maintained packages. Seurat is an R package that can perform QC, clustering, exploration, and visualization of scRNA-seq data, and they are regularly adding more features. It's a good place to start for us!\n",
    "\n",
    "If you're interested, they have many more useful vigenettes on their website: https://satijalab.org/seurat/get_started.html\n",
    "\n",
    "We installed Seurat for you already! So you can proceed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(Seurat)\n",
    "packageVersion(\"Seurat\")\n",
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Darmanis et al. dataset\n",
    "\n",
    "We're going to continue using the dataset we started working on in the prelab. \n",
    "\n",
    "This dataset is generated from human primary glioblastoma tumor cells with the Smart-seq2 protocol (https://www.ncbi.nlm.nih.gov/pubmed/29091775). We're using a subset of this dataset (n=1854 cells). The raw count matrix provided has been quantified using Salmon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in raw counts from Darmanis et al.\n",
    "sc_data <- read.table(\"~/22_Prelab_scRNAseq-I/data/unfiltered_darmanis_counts.tsv\", header=T, sep=\"\\t\", row.names=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the data. How many genes and how many cells are there in the raw dataset? What is the prefix of cell names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(sc_data)\n",
    "dim(sc_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What percentage of the data matrix is 0? Is this surprising?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## provide code here"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Seurat can do our QC and normalization\n",
    "\n",
    "Recall from the prelab that we looked at two QC metrics of interest: 1. number of reads detected per cell and 2. number of genes detected per cell. Now that we have a better understanding of these QC metrics, we can make our lives easier by using Seurat to visualize these QC stats (and more!) and filter out cells and features that don't pass QC metrics.\n",
    "\n",
    "If you're interested, you can get a lot more information about the Seurat package and its capabilities here: https://satijalab.org/seurat/get_started.html\n",
    "\n",
    "Before we start Seurat, we first want to convert Ensembl gene ids to HGNC symbols for easier interpretation. To save you time, we've provided you those annotations directly so that you can load them into R (Savvy students will note that you can get those from ensemble using the code that is commented out as you had in a previous module). Run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library(biomaRt)\n",
    "#ensembl <- useMart(\"ensembl\", dataset=\"hsapiens_gene_ensembl\")\n",
    "#bm <- getBM(attributes=c(\"ensembl_gene_id\", \"hgnc_symbol\"), values=rownames(sc_data), mart=ensembl)\n",
    "\n",
    "bm <- read.table(\"data/scRNASeq_annotations_r2.csv\", sep=\",\", header=T)\n",
    "\n",
    "hgnc.symbols <- bm$hgnc_symbol[match(rownames(sc_data), bm$ensembl_gene_id)]\n",
    "sc_data <- as.matrix(sc_data)\n",
    "rownames(sc_data) <- hgnc.symbols\n",
    "\n",
    "#Filter out any rows where the HGNC symbol is blank or NA\n",
    "sc_data <- subset(sc_data, rownames(sc_data) != \"\" & !is.na(rownames(sc_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1) We'll start by reading in our count data as a Seurat object. This object will hold our count matrix, as well as data for all downstream processing steps or analyses (normalization, scaling, PCA, clustering results, etc.). We can specify extra parameters to take only the features that are present in *min.cells* and the cells that have *min.features*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc <- CreateSeuratObject(counts=sc_data, project=\"Darmanis\", min.cells=5, min.features=200)\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original count matrix is stored in the assay called `RNA1, and a layer called `counts` \n",
    "\n",
    "You can access this in a very rough way: \n",
    "\n",
    "`sc[[\"RNA\"]]$counts`\n",
    "\n",
    "However, Seurat offers helper functions to access these data, e.g. the `LayerData()` function:\n",
    "\n",
    "`LayerData(sc, assay=\"RNA\", layer=\"counts\")`\n",
    "\n",
    "which also returns the equivalent matrix. Try them both out so you can see!\n",
    "\n",
    "Print the raw counts for the first 6 genes of the first 6 cells below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2) Seurat automatically generates the number of reads (nCount_RNA) and number of genes (nFeature_RNA) detected per cell. We can access this data in the `sc@meta.data` slot.\n",
    "\n",
    "\n",
    "Use ggplot to generate a density plot of nCount_RNA - it should exactly match the density plot we produced in the prelab for total read count!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(sc@meta.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3) One final QC metric we're often interested in is the percentage of reads mapping to the mitochondrial genome. A high percentage often indicates low-quality or dying cells. Seurat allows us to search for mitochondrial gene names and calculate the percentage of reads mapping to those genes. We can then stash these stats into our Seurat object's metadata by assigning `sc[[<metadata_feature_name>]]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc <- PercentageFeatureSet(object=sc, pattern=\"^MT-\", col.name=\"percent.mito\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would you have to change in the code above if we were working with mouse data?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4) How is the quality of this experiment? How do you know? We can visualize some QC metrics of interest in a violin plot. We can also check that the number of genes detected correlates with read count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VlnPlot(object=sc, features=c(\"nCount_RNA\", \"nFeature_RNA\", \"percent.mito\"), ncol=3, pt.size=0.5)\n",
    "FeatureScatter(object=sc, feature1=\"nCount_RNA\", feature2=\"nFeature_RNA\")\n",
    "\n",
    "## Note that the warning messages are Fine\n",
    "## you could remove them by running the follow before creating the Seurat Object:\n",
    "\n",
    "## options(Seurat.object.assay.calcn = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5) Remove low-quality cells (high mitochondrial content), empty droplets (low number of genes), doublets/multiplets (abnormally high number of genes). \n",
    "\n",
    "Seurat lets us easily apply QC filters based on our custom criteria. In this case, we want cells with >250 genes, but less than 2500, and <10% mitochondrial content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc <- subset(sc, subset = nFeature_RNA > 250 & nFeature_RNA < 2500 & percent.mito < 10)\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many genes and cells remain after QC?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 6) Recover cell type annotations, stash in `sc@meta.data`\n",
    "\n",
    "Run the following code to add cell type annotations to our Seurat object metadata. This will be useful later when we're visualizing the different cell populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_metadata <- read.table(\"~/22_Prelab_scRNAseq-I/data/unfiltered_darmanis_metadata.tsv\", sep=\"\\t\", header=T)\n",
    "\n",
    "celltypes <- sc_metadata$cell.type.ch1[match(rownames(sc@meta.data), sc_metadata$geo_accession)]\n",
    "sc@meta.data$celltype <- celltypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the metadata for the first 6 cells below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 7) Normalization, variable feature identification, and scaling\n",
    "\n",
    "The default in Seurat v5 is SCTransform (v2), a modeling framework for the normalization and variance stabilization of molecular count data from scRNA-seq experiments.\n",
    "\n",
    "Initially, described in PMID: 31870423, this method proposes a generalized linear model for each gene, predicting UMI counts (response variable) from sequencing depth (predictor variable). The key initial idea of this method is rather than use a negative binomial or \"zero-inflated\" negative binomial model (to handle sparsity) for every gene - which can cause model over fitting and reduce signal - to instead pool genes with similar abundance in order to reduce the number of parameters for the estimated variances underlying the model for error (i.e., 'regularization') that explain variance in the data well. Hence, the model is a \"regularized\" binomial model regression (regression then allowing inclusion of confounding covariates, like mitochondrial percentage). This work describes SCTransform (v1).\n",
    "\n",
    "PMID: 34488842 provided an updated version (v2), which includes three major modifications to the initial approach: (1) fixing the slope of the negative binomial GLM to ln(10) - the analytically derived solution - so that only overdispersion and intercept parameters are estimated per gene, (2) removal of genes from regularization that have very low expression or where the variance of molecular counts does not exceed the mean; instead, setting parameter choices there to capture a Poisson model, and (3) application of a lower bound of the minimum variance while calculating the Pearson's residual for each per cell to prevent genes with minimal information from resulting in high residual variance, ensuring that very low UMI counts are not assigned very high Pearson residuals.\n",
    "\n",
    "This procedure omits the need for heuristic steps including pseudocount addition or log-transformation and improves common downstream analytical tasks such as variable gene selection, dimensional reduction, and differential expression.\n",
    "\n",
    "This step will take a little bit of time, so be patient! (around 6-7 minutes!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sc_sct <- SCTransform(sc, vars.to.regress = \"percent.mito\", verbose = FALSE)\n",
    "\n",
    "# This is another way to normalize for your reference\n",
    "#sc <- NormalizeData(object=sc, normalization.method = \"LogNormalize\", scale.factor=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, print the scaled counts for the first 6 genes of the first 6 cells, comparing the original count data to the rescaled data.\n",
    "\n",
    "**TIP**: Use the `LayerData` functions described above for this. In Seurat, the results from the SCTransform procedure with re-scaling are stored as a new assay types named `SCT`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## code for original count data here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code for SCT scaled data here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 8) Compare normalized data to raw count data\n",
    "\n",
    "Let's look at how proper data processing impacts our ability to draw interpretable conclusions about the biology. We'll generate PCA plots for a simple normalization based on raw counts data and the SCT procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Runs PCA on SCT-processed data\n",
    "sc_sct <- RunPCA(sc_sct, verbose=FALSE)\n",
    "DimPlot(sc_sct, dims = c(1, 2), reduction=\"pca\", label=FALSE, group.by=\"celltype\")\n",
    "pca_plot_sct <- DimPlot(sc_sct, dims = c(1, 2), reduction=\"pca\", label=FALSE, group.by=\"celltype\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs PCA using a more basic normalization and data processing procedure\n",
    "sc_scale <- NormalizeData(sc, normalization.method = \"RC\")\n",
    "sc_scale <- FindVariableFeatures(sc_scale, verbose=FALSE)\n",
    "sc_scale <- ScaleData(sc_scale, verbose=FALSE)\n",
    "sc_scale <- RunPCA(sc_scale, verbose=FALSE)\n",
    "\n",
    "DimPlot(sc_scale, dims = c(1, 2), reduction=\"pca\", label=FALSE, group.by=\"celltype\")\n",
    "#pca_plot_raw <- DimPlot(sc, dims = c(1, 2), reduction=\"pca\", label=FALSE, group.by=\"celltype\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see any differences in the above plots? What are they?\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 9) Finally, save your processed Seurat object for future downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveRDS(sc, file=\"sc_Darmanis_normalized.rds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage Two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### We're going to be analyzing the Zheng et al. dataset (https://www.nature.com/articles/ncomms14049). This dataset consists of 68k FACS-sorted immune cells from peripheral blood. We'll use a small downsampled subset to save time and memory. \n",
    "\n",
    "###### Using what you've learned above, process the Zheng et al. dataset. You DON'T need to rerun every step, only the ones essential for producing the final processed Seurat object. \n",
    "\n",
    "######  These steps include: \n",
    "1. Visualize QC metrics\n",
    "2. Filter out low-quality cells and lowly expressed genes. Criteria: nFeature_RNA > 500, nFeature_RNA < 2500, percent.mito < 10\n",
    "3. Normalize\n",
    "4. Scale, regress out mitochondrial content variable\n",
    "5. Save the filtered, processed Seurat object\n",
    "\n",
    "###### Make sure to include all essential code!\n",
    "\n",
    "###### Tip: you can set image plotting sizes via `options(repr.plot.width=..., repr.plot.height=...)` which will help the sizing of these a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We loaded in the data for you\n",
    "Zheng_data <- read.table(\"data/Zheng_pbmc_downsample300_C9_filt_r2.txt\", sep=\"\\t\", header=T, check.names=F)\n",
    "\n",
    "geneids <- as.character(Zheng_data[,ncol(Zheng_data)])\n",
    "Zheng_data$gene_symbols <- NULL\n",
    "Zheng_data <- as.matrix(Zheng_data)\n",
    "rownames(Zheng_data) <- geneids\n",
    "\n",
    "# Create Seurat object\n",
    "sc <- CreateSeuratObject(counts=Zheng_data, project=\"Zheng2017\")\n",
    "\n",
    "# Store type information in meta data object\n",
    "celltype <- sapply(strsplit(rownames(sc@meta.data), split=\"_\"), function(x) x[[2]])\n",
    "sc@meta.data$celltype <- celltype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.** (a) Visualize QC metrics of interest and (b) filter out poor-quality cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize QC metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out poor-quality cells\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.** Apply SCTransform and make sure to regress out mitochondrial contamination in the scale step. Save this to an variable named `sc` (e.g. overwrite the current `sc` variable). \n",
    "\n",
    "Run PCA on the SCT-processed data and visuale the output.\n",
    "\n",
    "Use `saveRDS()` to save the Seurat object as an .rds object named `sc_Zheng_normlized.rds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply SCTransform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs PCA on SCT-processed data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use saveRDS() to save the Seurat Object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3** In Seurat and in the context of dimensional reduction, what is the goal? What is meant by an \"embedding\" and \"loading\" - What are those objects and what do they represent?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The objective of this approach is to take large matrix \\(or tensors\\) of data and reduce to a compact set of factors and features that can be more easily visualized and utilized in downstream analysis. In this context, we are reducing a giant matrix of single cells \\- cross \\- normalized transcript abundance into a smaller set of components that capture similarities across cells. \n",
    "\n",
    "The embedding matrix is a lower\\-dimensional representation of expression for each single\\-cell. In the above case, that's Principal Components analysis, but could be other components with other schemes \\(e.g. UMAP, tSNE, etc.\\). \n",
    "\n",
    "The loadings matrix represents how much each gene contributes to each lower\\-dimensional component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4** Reviewing the [list of basic commands available on Seurat's website](https://satijalab.org/seurat/articles/seurat5_essential_commands), output the embeddings and save the embeddings matrix to a file called: `Zheng_pca_embeddings_output.txt`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## wrote this code de novo, could carry bugged\n",
    "Zhang_embeddings <- Embeddings(sc, reduction = \"pca\")\n",
    "write.table(Zhang_embeddings, file=\"Zheng_pca_embeddings_output.txt\", row.names=F, quote=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5** What are the primary sources of technical variability and biases you would be worried about in this experiment? See Zheng et al. for information about the experiment and Ziegenhain et al. for an overview of scRNA-seq technical biases (both papers are in your directory)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The primary sources of technical variability and biases that I would be worried about here are (a) a bias in amplification (droplet-based scRNA seq methods have higher amplification nosie than other methods) and (b) low sensitivity (by using the number of detected genes per cell as a measure of sensitivity, droplet-based methods can be classified as having low sensitivity). In general, these papers indicate that technical variability/biases can include those related to the sensitivity (probability to capture and convert a particular mRNA transcript present into a single cell into a cDNA molecule present in the library), accuracy (how well the read quantification corresponds to the actual concentration of mRNA), precision with which amplification occurs (technical variation of the quantification), and the number of cells anaylzed."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
